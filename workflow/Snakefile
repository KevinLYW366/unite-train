# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

from snakemake.io import glob_wildcards, expand

VERSION = ["ver8"]
CLUSTER = [
    "97",
    "99",
    "dynamic"
    ]
TYPE = [
    "",      # Fungi, Includes singletons set as RefS (in dynamic files).
    "s_",    # Fungi, Includes global and 97% singletons.
    "all_",  # All Euks, Includes singletons set as RefS (in dynamic files).
    "s_all_" # All Euks, Includes global and 97% singletons.
    ]
DATE = ["10.05.2021"]

GOALS = expand("results/unite_{ver}_{id}_{type}{date}.qza", ver=VERSION, id=CLUSTER, type=TYPE, date=DATE)
# print(GOALS)

rule all:
    input: GOALS

checkpoint download: # This is not proper snakemake. I can't get my tuples to work.
    output:
        #ref=temp("downloads/sh_refs_qiime_{ver}_{id}_{type}{date}_dev.fasta"),
        #tax=temp("downloads/sh_taxonomy_qiime_{ver}_{id}_{type}{date}_dev.txt")
        # Note the messy wildcards in rule.reformat_seqs and rule.import_tax this requires
        dir=temp(directory("downloads/")) 
    # conda: # TODO: troubleshoot this and pin wget and tar versions
    #      "envs/unix.yaml"
    threads: 1000
    shell:
        """
        mkdir -p downloads
        # 8.3	2021-05-10	Fungi	14 097	44 343	Current	https://doi.org/10.15156/BIO/1264708
        wget -qO- https://files.plutof.ut.ee/public/orig/C5/54/C5547B97AAA979E45F79DC4C8C4B12113389343D7588716B5AD330F8BDB300C9.tgz | tar xz -C downloads --strip-components 2 # sh_qiime_release_10.05.2021       # normal
        # 8.3	2021-05-10	Fungi	14 097	83 993	Current	https://doi.org/10.15156/BIO/1264763
        wget -qO- https://files.plutof.ut.ee/public/orig/B3/05/B3054DF783AC61A0C3BD0FDEB0516EC394934809AAE43CA0F3081C0A184FAA39.tgz | tar xz -C downloads --strip-components 2 # sh_qiime_release_s_10.05.2021     # add s for 97% singletons
        # 8.3	2021-05-10	All eukaryotes	14 237	96 423	Current	https://doi.org/10.15156/BIO/1264819
        wget -qO- https://files.plutof.ut.ee/public/orig/48/29/4829D91F763E20F0F4376A60AA53FC9FBE6029A7D1BDC1B45347DD64EDE5D560.tgz | tar xz -C downloads --strip-components 2 # sh_qiime_release_all_10.05.2021   # add all for Euks
        # 8.3	2021-05-10	All eukaryotes	14 237	190 888	Current	https://doi.org/10.15156/BIO/1264861
        wget -qO- https://files.plutof.ut.ee/public/orig/1D/31/1D31FA3A308BDC2FB2750D62C0AA40C5058C15405A3CC5C626CC3A3F5E3903ED.tgz | tar xz -C downloads --strip-components 2 # sh_qiime_release_s_all_10.05.2021 # and s and all for 97% Euks singletons
        """

rule reformat_seqs:
    input: "downloads"
    output: temp("results/sh_refs_qiime_{ver}_{id}_{type}{date}_dev.fixed.fasta")
    threads: 2
    shell: "awk '/^>/ {{print($0)}}; /^[^>]/ {{print(toupper($0))}}' \
            {input}/sh_refs_qiime_{wildcards.ver}_{wildcards.id}_{wildcards.type}{wildcards.date}_dev.fasta | \
            tr -d ' ' > {output}"

rule import_seqs:
    input:  "results/sh_refs_qiime_{ver}_{id}_{type}{date}_dev.fixed.fasta"
    output: temp("results/sh_refs_qiime_{ver}_{id}_{type}{date}_dev.qza")
    threads: 2
    shell: "qiime tools import --type FeatureData[Sequence] \
            --input-path {input} \
            --output-path {output}"

rule import_tax:
    input: "downloads"
    output:temp("results/sh_taxa_qiime_{ver}_{id}_{type}{date}_dev.qza")
    threads: 2
    shell: "qiime tools import --type FeatureData[Taxonomy] \
            --input-format HeaderlessTSVTaxonomyFormat \
            --input-path {input}/sh_taxonomy_qiime_{wildcards.ver}_{wildcards.id}_{wildcards.type}{wildcards.date}_dev.txt \
            --output-path {output}"

rule train:
    input:
        ref=rules.import_seqs.output,
        tax=rules.import_tax.output
    output: protected("results/unite_{ver}_{id}_{type}{date}.qza")
    threads: 1000
    shell: "qiime feature-classifier fit-classifier-naive-bayes \
            --p-classify--chunk-size 10000 \
            --i-reference-reads    {input.ref} \
            --i-reference-taxonomy {input.tax} \
            --o-classifier {output}"
